{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T08:11:44.357304Z",
     "start_time": "2021-09-19T08:11:43.338418Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This examples trains a CrossEncoder for the NLI task. A CrossEncoder takes a sentence pair\n",
    "as input and outputs a label. Here, it learns to predict the labels: \"contradiction\": 0, \"entailment\": 1, \"neutral\": 2.\n",
    "It does NOT produce a sentence embedding and does NOT work for individual sentences.\n",
    "Usage:\n",
    "python training_nli.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import LoggingHandler, util\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CESoftmaxAccuracyEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T08:12:21.783820Z",
     "start_time": "2021-09-19T08:12:10.480348Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "logger = logging.getLogger(__name__)\n",
    "#### /print debug information to stdout\n",
    "\n",
    "\n",
    "#As dataset, we use SNLI + MultiNLI\n",
    "#Check if dataset exsist. If not, download and extract  it\n",
    "nli_dataset_path = 'allnli_mixed_final.tsv.gz'\n",
    "\n",
    "\n",
    "# Read the AllNLI.tsv.gz file and create the training dataset\n",
    "logger.info(\"Read AllNLI train dataset\")\n",
    "\n",
    "label2int = {\"contradiction\": 0, \"entailment\": 1, \"neutral\": 2}\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "\n",
    "i=0\n",
    "with gzip.open(nli_dataset_path, 'rt', encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        try:\n",
    "\n",
    "            label_id = label2int[row['label']]\n",
    "            if row['split'] == 'train':\n",
    "                train_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=label_id))\n",
    "            elif row['split'] == 'test':\n",
    "                test_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=label_id))\n",
    "            else:\n",
    "                dev_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=label_id))\n",
    "        except:\n",
    "            i+=1\n",
    "            #print(i, row)\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T16:04:34.524914Z",
     "start_time": "2021-09-19T08:12:49.367548Z"
    }
   },
   "outputs": [],
   "source": [
    "train_batch_size = 6\n",
    "num_epochs = 1\n",
    "model_save_path = 'output/training_allnli-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "#Define our CrossEncoder model. We use distilroberta-base as basis and setup it up to predict 3 labels\n",
    "model = CrossEncoder('cross-encoder/nli-deberta-base', num_labels=len(label2int))\n",
    "\n",
    "#We wrap train_samples, which is a list ot InputExample, in a pytorch DataLoader\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "#During training, we use CESoftmaxAccuracyEvaluator to measure the accuracy on the dev set.\n",
    "evaluator = CESoftmaxAccuracyEvaluator.from_input_examples(dev_samples, name='AllNLI-dev')\n",
    "\n",
    "\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "logger.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=10000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          use_amp= True,\n",
    "          save_best_model=True,\n",
    "          output_path=model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda110",
   "language": "python",
   "name": "cuda110"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
